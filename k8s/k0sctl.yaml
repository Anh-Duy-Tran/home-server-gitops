apiVersion: k0sctl.k0sproject.io/v1beta1
kind: Cluster
metadata:
  name: k0s-cluster
  user: admin
spec:
  hosts:
    - role: single
      ssh:
        address: 192.168.50.240
        user: duytran
        port: 22
        keyPath: ~/.ssh/id_rsa
      installFlags:
        - --debug
      hooks:
        # Comment this out if the target host doesn't have firewall problem
        apply:
          before:
            - sudo iptables-restore < /etc/iptables/iptables.rules
      files:
        - name: metallb-ipaddresspool
          src: ./metallb/IPAddressPool.yaml
          dstDir: /var/lib/k0s/manifests/metallb/
          perm: 0644
        - name: cloudflare-tunnel-secrets
          src: ./cloudflare-tunnel/cloudflare-tunnel-secret.yaml
          dstDir: /var/lib/k0s/manifests/cloudflare-tunnel/
          perm: 0644
        - name: minio-persistent-pv
          src: ./minio/minio-persistent-pv.yaml
          dstDir: /var/lib/k0s/manifests/storage/
          perm: 0644
        - name: velero-auto-restore
          src: ./velero/auto-restore-config.yaml
          dstDir: /var/lib/k0s/manifests/velero/
          perm: 0644
  k0s:
    config:
      apiVersion: k0s.k0sproject.io/v1beta1
      kind: Cluster
      metadata:
        name: k0s
      spec:
        extensions:
          helm:
            concurrencyLevel: 5
            repositories:
              - name: traefik
                url: https://traefik.github.io/charts
              - name: metallb
                url: https://metallb.github.io/metallb
              - name: openebs
                url: "https://openebs.github.io/charts"
              - name: argocd
                url: https://argoproj.github.io/argo-helm
              - name: cloudflare
                url: https://cloudflare.github.io/helm-charts
              - name: minio
                url: https://charts.min.io/
              - name: vmware-tanzu
                url: https://vmware-tanzu.github.io/helm-charts
            charts:
              - name: metallb
                order: 1
                chartname: metallb/metallb
                version: 0.15.2
                namespace: metallb-system
              - name: openebs
                chartname: openebs/openebs
                version: 3.10.0
                namespace: openebs
                order: 1
                values: |
                  localprovisioner:
                    hostpathClass:
                      enabled: true
                      isDefaultClass: true
                    basePath: /var/openebs/local
              - name: traefik
                order: 2
                chartname: traefik/traefik
                version: 34.3.0
                namespace: traefik
                values: |
                  additionalArguments:
                    - --log.level=DEBUG
                    - --api
                    - --api.dashboard=true
                    - --api.insecure=true
                  providers:
                    kubernetesIngress:
                      publishedService:
                        enabled: true
              - name: minio
                order: 2
                chartname: minio/minio
                version: 5.2.0
                namespace: minio
                values: |
                  mode: standalone
                  replicas: 1
                  persistence:
                    enabled: true
                    existingClaim: minio
                  resources:
                    requests:
                      memory: 512Mi
                      cpu: 100m
                    limits:
                      memory: 2Gi
                      cpu: 1000m
                  rootUser: minioadmin
                  rootPassword: minioadmin123
                  service:
                    type: ClusterIP
                  consoleService:
                    type: LoadBalancer
                  buckets:
                    - name: velero
                      policy: none
                      purge: false
              - name: velero
                order: 3
                chartname: vmware-tanzu/velero
                version: 7.2.1
                namespace: velero
                values: |
                  upgradeCRDs: false
                  cleanUpCRDs: false
                  # Enable node-agent for file-system backups
                  deployNodeAgent: true
                  nodeAgent:
                    podVolumePath: /var/lib/k0s/kubelet/pods
                  configuration:
                    backupStorageLocation:
                      - name: default
                        provider: aws
                        bucket: velero
                        config:
                          region: minio
                          s3ForcePathStyle: "true"
                          s3Url: http://minio.minio:9000
                    volumeSnapshotLocation:
                      - name: default
                        provider: aws
                        config:
                          region: minio
                  credentials:
                    useSecret: true
                    secretContents:
                      cloud: |
                        [default]
                        aws_access_key_id=minioadmin
                        aws_secret_access_key=minioadmin123
                  initContainers:
                    - name: velero-plugin-for-aws
                      image: velero/velero-plugin-for-aws:v1.10.0
                      volumeMounts:
                        - mountPath: /target
                          name: plugins
                  schedules:
                    daily-backup:
                      disabled: false
                      schedule: "0 2 * * *"
                      template:
                        ttl: "720h"
                        includedNamespaces:
                          - stateful-apps
                        # Only backup PVC data, not manifests (managed by GitOps)
                        includedResources:
                          - persistentvolumeclaims
                          - persistentvolumes
                        # Enable file-system backup for all PVCs
                        defaultVolumesToFsBackup: true
              - name: argocd
                order: 4
                chartname: argocd/argo-cd
                version: 7.7.12
                namespace: argocd
                values: |
                  server:
                    service:
                      type: LoadBalancer
                  configs:
                    params:
                      server.insecure: true
              - name: cloudflare-tunnel
                order: 4
                chartname: cloudflare/cloudflare-tunnel
                version: 0.3.2
                namespace: cloudflare-tunnel
                values: |
                  cloudflare:
                    account: "228f7adda0389734d880eeb14f621c5a"
                    tunnelName: "super-cluster-tunnel"
                    tunnelId: "4a026bef-fd4f-46d4-9f1c-39fb5be523ca"
                    secretName: cloudflare-tunnel-secrets
                    enableWarp: false
                    ingress:
                      # ArgoCD Admin UI - Direct access
                      - hostname: argocd.duytran.app
                        service: http://argocd-server.argocd:80
                      # All other services - Route through Traefik ingress controller
                      - hostname: "*.duytran.app"
                        service: http://traefik.traefik:80
        api:
          k0sApiPort: 9443
          port: 6443
        installConfig:
          users:
            etcdUser: etcd
            kineUser: kube-apiserver
            konnectivityUser: konnectivity-server
            kubeAPIserverUser: kube-apiserver
            kubeSchedulerUser: kube-scheduler
        konnectivity:
          adminPort: 8133
          agentPort: 8132
        network:
          kubeProxy:
            disabled: false
            mode: iptables
          kuberouter:
            autoMTU: true
            mtu: 0
            peerRouterASNs: ""
            peerRouterIPs: ""
          podCIDR: 10.244.0.0/16
          provider: kuberouter
          serviceCIDR: 10.96.0.0/12
        podSecurityPolicy:
          defaultPolicy: 00-k0s-privileged
        storage:
          type: etcd
        telemetry:
          enabled: true
  options:
    wait:
      enabled: true
    drain:
      enabled: true
      gracePeriod: 2m0s
      timeout: 5m0s
      force: true
      ignoreDaemonSets: true
      deleteEmptyDirData: true
      podSelector: ""
      skipWaitForDeleteTimeout: 0s
    concurrency:
      limit: 30
      uploads: 5
    evictTaint:
      enabled: false
      taint: k0sctl.k0sproject.io/evict=true
      effect: NoExecute
      controllerWorkers: false
